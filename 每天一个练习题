相关知识点文档参考：  
                 1.用户密码存储与Python示例
                 2.Hashing String with python

        每天一个练习题

1.在一个指定图片上加上一个数字0或者1

2.为APP应用生成激活码（或者优惠券码），使用Python生成200个激活码

3.将上面生成的200个激活码保存到Mysql关系型数据库和redis非关系型数据库中

4.在一个英文纯文本文件中，统计其中单词出现的个数

5.把指定目录中所有像素的图片转换成不大于iPhone5分辨率大小

6.一个目录放到很多日记，全是txt格式，统计每篇日记中最重要的词（）

7.一个HTML文件，找出里面的正文和所有连接（正则匹配的用法）

8.使用Python生成类似数字字母验证码的验证码图片

9.敏感词提示：建立一个敏感词文件，只要句子中出现文件库中的敏感词，就用**将敏感词替代

10.纯文本文件，student.txt  {"1":["张三，150100,102"]，“2”：[“李四”，120,130,100]}
   将上述内容写到student.xls文件中

习题4：
     步骤1：去掉标点符号  采用方式可以去停词或者直接用replace去掉，但是后者花费的时间应该会长一些
         2.切割分词，采用精确模式切分，因为全模式导致的重复词汇太多
    s='我们在北京，我们过得很好，很不错'
    s=s.replace(r'，',' ')
    print("/".join(jieba.cut(s,cut_all=False)))#切分句子
    b=jieba.analyse.textrank(string1, topK = 3, withWeight = True)  #获取权重最大的三个值
    print(b,'==========================')


习题6：
# _*_ coding:utf-8 _*_
import jieba
import jieba.posseg as pseg
import jieba.analyse

with open('Test.txt','r') as f: #读取文本
    string1=f.read()
    print (string1)
    print('===============')
    words=pseg.cut(string1)#进行分词
    result=''#记录最终结果的变量
    b=jieba.analyse.textrank(string1, topK = 3, withWeight = True)  #获取权重最大的三个值
    # for w in words:
    #     result +=str(w.word)+"/"+str(w.flag)  #加词性标注
    # print (result)
    
    
    
